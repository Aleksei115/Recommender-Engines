{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import time \n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to download 6 different categories, we want to create different collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_review = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\",\"raw_review_All_Beauty\", split=\"full\", trust_remote_code=True)\n",
    "dataset1_meta = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\",\"raw_meta_All_Beauty\", split=\"full\", trust_remote_code=True)\n",
    "\n",
    "dataset2_review = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\",\"raw_review_Cell_Phones_and_Accessories\", split=\"full\", trust_remote_code=True)\n",
    "dataset2_meta = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\",\"raw_meta_Cell_Phones_and_Accessories\", split=\"full\", trust_remote_code=True)\n",
    "\n",
    "dataset3_review = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\",\"raw_review_Video_Games\", split=\"full\", trust_remote_code=True)\n",
    "dataset3_meta = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\",\"raw_meta_Video_Games\", split=\"full\", trust_remote_code=True)\n",
    "\n",
    "\n",
    "datasets_meta = [dataset1_meta,dataset2_meta,dataset3_meta]\n",
    "datasets_reviews = [dataset1_review,dataset2_review,dataset3_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectDB:\n",
    "    def __init__(self) -> None:\n",
    "        self.client = client = MongoClient(\"mongodb://localhost:27017\")\n",
    "        self.db = db = client.massiveData\n",
    "    \n",
    "    def create_collection(self,name):\n",
    "        collection = self.db[name]\n",
    "        return None\n",
    "\n",
    "    def get_collection(self,name):\n",
    "        collection = self.db[name]\n",
    "        return collection\n",
    "\n",
    "# products_df = pd.DataFrame()\n",
    "\n",
    "class InfoLoader:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def create_review(self,dataset, date= '2023-01-01'):\n",
    "        \"\"\"\n",
    "        Prepare a dataset to be added to a collection.\n",
    "        Input:\n",
    "            - Array of raw metadata of reviews.\n",
    "            - Date since we want the first review.\n",
    "        Output:\n",
    "            - Reviews transformed to be added to a collection filtered for a timestamp.\n",
    "        \"\"\"\n",
    "        reviews = []\n",
    "\n",
    "        i = 0\n",
    "        for review in dataset:\n",
    "\n",
    "\n",
    "            # Calculate the timestamp from 01/01/2022 \n",
    "            ts_2022 = pd.Timestamp(date).timestamp() * 1000\n",
    "\n",
    "\n",
    "            if review['verified_purchase'] is True and review['timestamp'] > ts_2022:\n",
    "            \n",
    "                aux_review = {}\n",
    "                aux_review['rating'] = review['rating']\n",
    "\n",
    "                #Que tengan un titulo similar \n",
    "                aux_review['title'] = review['title']\n",
    "\n",
    "                #Analisis de sentimientos o reviews parecidas\n",
    "                aux_review['text'] = review['text']\n",
    "\n",
    "                #Producto asociado recomendar productos no comprados\n",
    "                aux_review['id_product'] = review['parent_asin']\n",
    "\n",
    "                #Producto asociado\n",
    "                aux_review['id_user'] = review['user_id']\n",
    "\n",
    "                #Compra verificada\n",
    "                aux_review['verified_purchase'] = review['verified_purchase']\n",
    "\n",
    "                aux_review['helpful_vote'] = review['helpful_vote']\n",
    "\n",
    "\n",
    "                aux_review['url'] = 'https://amazon.com.mx/' + review['parent_asin']\n",
    "\n",
    "                reviews.append(aux_review)\n",
    "\n",
    "        return reviews\n",
    "\n",
    "    def create_metadata(self,dataset):\n",
    "        \"\"\"\n",
    "        Prepare a dataset to be added to a collection\n",
    "        input: \n",
    "            Array of raw metadata of products\n",
    "        output:\n",
    "            Products transformed to be added to a collection\n",
    "        \"\"\"\n",
    "        products = []\n",
    "        for product in dataset:\n",
    "\n",
    "            aux_product = {}\n",
    "\n",
    "            aux_product['id'] = product['parent_asin']\n",
    "\n",
    "            #Que tengan un titulo similar \n",
    "            aux_product['title'] = product['title']\n",
    "\n",
    "\n",
    "            #Que tengan una categoria similar \n",
    "            aux_cat = ''\n",
    "            #Add any categories that the product has, limited by 3\n",
    "            for i,cat in enumerate(product['categories']):\n",
    "                aux_cat += cat + ','\n",
    "            aux_product[f\"categorie\"] = aux_cat\n",
    "            \n",
    "\n",
    "            aux_product['price'] = product['price'] or -1\n",
    "            \n",
    "            # Que tengan descripcion similar\n",
    "            aux_product[\"description\"] = product['description'] or np.nan\n",
    "\n",
    "            aux_product[\"features\"] = product['features'] or np.nan\n",
    "\n",
    "            if len(product['images']['large']) > 0:\n",
    "                aux_product[\"img\"] = product['images']['large'][0] or np.nan\n",
    "            else:\n",
    "                aux_product[\"img\"] = ''\n",
    "                \n",
    "            aux_product['avg_rating'] = product['average_rating'] or np.nan\n",
    "\n",
    "            aux_product['url'] = 'https://amazon.com.mx/' + product['parent_asin']\n",
    "\n",
    "            products.append(aux_product)\n",
    "\n",
    "\n",
    "        return products\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the Reviews and Metadata to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create 2 collections \n",
    "    1. Reviews\n",
    "    2. Products\n",
    "2. Transform the original datasets for both meta and reviews for each category\n",
    "3. Load collections and add the transformed datasets to their respective collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = ConnectDB()\n",
    "infl = InfoLoader()\n",
    "\n",
    "\n",
    "# Step 1: Create 2 collections\n",
    "db.create_collection('reviews')\n",
    "db.create_collection('products')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time it took to finish this ETL was 215 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Transform the original datasets\n",
    "datasets_meta_transformed = []\n",
    "datasets_reviews_transformed = []\n",
    "for meta,review in zip(datasets_meta,datasets_reviews):\n",
    "    datasets_meta_transformed.append(infl.create_metadata(meta))\n",
    "    datasets_reviews_transformed.append(infl.create_review(review))\n",
    "    \n",
    "\n",
    "to_meta =  [item for sublist in datasets_meta_transformed for item in sublist]\n",
    "to_reviews = [item for sublist in datasets_reviews_transformed for item in sublist]\n",
    "\n",
    "products_df = pd.DataFrame(to_meta)\n",
    "products_df.to_csv('./datasets_meta_transformed.csv',index=False)\n",
    "\n",
    "reviews_df = pd.DataFrame(to_reviews)\n",
    "reviews_df.to_csv('./datasets_reviews_transformed.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv('./datasets_reviews_transformed.csv')\n",
    "\n",
    "reviews_exported = df_reviews.to_dict(orient='records')\n",
    "\n",
    "reviews_collection = db.get_collection('reviews')\n",
    "\n",
    "reviews_collection.insert_many(reviews_exported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv('./datasets_meta_transformed.csv')\n",
    "\n",
    "meta_exported = df_meta.to_dict(orient='records')\n",
    "\n",
    "products_collection = db.get_collection('products')\n",
    "\n",
    "products_collection.insert_many(meta_exported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult({'n': 1538349, 'nModified': 1538349, 'ok': 1.0, 'updatedExisting': True}, acknowledged=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_collection = db.get_collection('products')\n",
    "products_collection.update_many({}, {\"$rename\": {\"id\": \"id_product\"}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
